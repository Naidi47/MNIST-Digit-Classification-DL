
#  MNIST Digit Classification using PyTorch

This project implements a **Convolutional Neural Network (CNN)** to classify handwritten digits (0â€“9) from the MNIST dataset using PyTorch.  
The notebook is clean, beginnerâ€‘friendly, and designed for Google Colab.

---

# ğŸ“ Folder Structure

```
mnist-digit-classification/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ mnist_cnn.ipynb
â”‚
â”œâ”€â”€ data/                     # auto-downloaded MNIST dataset
â”‚
â””â”€â”€ saved_models/
    â””â”€â”€ mnist_cnn_best.pth    # saved trained model
```

---

#  Project Objective

Train a deep learning model that can accurately classify handwritten digits from 28Ã—28 grayscale images.

Dataset:
- **60,000 training images**
- **10,000 testing images**
- **10 classes (0â€“9)**

---

#  Features

- Simple & effective CNN model
- Achieves **98â€“99% accuracy**
- Includes full training + testing
- Includes inference on single images
- Runs smoothly on **Google Colab GPU**
- Beginnerâ€‘friendly explanations

---

#  Key Deep Learning Concepts

### âœ” Convolutional Layers  
Extract detectable features (edges, shapes).

### âœ” ReLU Activation  
Introduces non-linearity for complex learning.

### âœ” MaxPooling  
Reduces image size â†’ faster training â†’ less overfitting.

### âœ” Dropout  
Prevents overfitting by randomly dropping neurons.

### âœ” CrossEntropy Loss  
Standard loss for multi-class classification.

### âœ” Adam Optimizer  
Fast convergence with adaptive learning rate.

---

#  Model Architecture

```
Input: 1 Ã— 28 Ã— 28 grayscale image

Conv2d(1 â†’ 32) â†’ ReLU â†’ MaxPool
Conv2d(32 â†’ 64) â†’ ReLU â†’ MaxPool

Flatten  â†’  3136 features

Linear(3136 â†’ 128) â†’ ReLU â†’ Dropout(0.5)
Linear(128 â†’ 10)

Output: 10 class logits
```

---

# ğŸ“Š Expected Results

### â€¢ Training Accuracy: **~99%**  
### â€¢ Test Accuracy: **98â€“99%**

Example output:

```
Epoch 1: Train Acc = 97.8% | Test Acc = 98.4%
Epoch 2: Train Acc = 98.9% | Test Acc = 99.1%
Epoch 3: Train Acc = 99.3% | Test Acc = 99.1%
```

Loss and accuracy curves are automatically generated in the notebook.

---

#  How to Use (Google Colab)

### **1. Upload notebook**
Upload **mnist_cnn.ipynb** to Google Colab.

### **2. Enable GPU**
`Runtime â†’ Change runtime type â†’ GPU`

### **3. Run all cells**
Training will begin, evaluate, and save the model to:

```
saved_models/mnist_cnn_best.pth
```

---

#  Example Prediction

```
True Label: 5
Predicted Label: 5
```

The notebook visualizes the digit and shows prediction.

---

#  Possible Enhancements

- Add BatchNorm layers  
- Add lr scheduler  
- Add early stopping  
- Add confusion matrix  
- Visualize CNN filters  
- Use Gradâ€‘CAM for heatmaps  
- Convert model to ONNX  

---

## ğŸ‘¨â€ğŸ’» Author Details

Name: M. Brahmanaidu (Muchukuntla Brahmanaidu)
Role: Data Science / AI & ML Aspirant Developer
Email: muchukuntlabrahmanaidu@gmail.com

GitHub: https://github.com/Naidi47

LinkedIn: https://www.linkedin.com/in/brahmanaidu-muchukuntla-17a1a9242/
